{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning Tutorial with Python and Pandas\n",
        "\n",
        "Welcome to this interactive tutorial on Data Cleaning! \n",
        "\n",
        "Data cleaning is a crucial step in any data science or machine learning project. Real-world data is often \"messy\"—it contains missing values, duplicates, errors, and inconsistencies. If we feed this messy data into our models, the results will be unreliable (Garbage In, Garbage Out).\n",
        "\n",
        "In this notebook, we will cover:\n",
        "1.  **Generating Synthetic Data**: Creating a messy dataset to practice on.\n",
        "2.  **Data Inspection**: Understanding the structure and issues in your data.\n",
        "3.  **Handling Missing Values**: Deciding whether to drop or fill missing data.\n",
        "4.  **Removing Duplicates**: Identifying and deleting repeated entries.\n",
        "5.  **Fixing Inconsistencies**: Standardizing text and categorical data.\n",
        "6.  **Handling Outliers**: Detecting and managing extreme values.\n",
        "7.  **Type Conversion**: Ensuring data types are correct for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generating a \"Messy\" Dataset\n",
        "\n",
        "To ensure everyone has the same data and to demonstrate specific cleaning challenges, we will generate a synthetic dataset representing a **Customer Database**.\n",
        "\n",
        "Our dataset will intentionally include:\n",
        "-   **Missing Values (`NaN`)**: Simulating incomplete forms.\n",
        "-   **Duplicates**: Simulating data entry errors.\n",
        "-   **Inconsistent Text**: e.g., \"New York\", \"new york\", \"NY\".\n",
        "-   **Outliers**: e.g., an Age of 200.\n",
        "-   **Wrong Data Types**: Numbers stored as strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a dictionary of data\n",
        "data = {\n",
        "    'CustomerID': [101, 102, 103, 104, 105, 106, 107, 108, 109, 101, 110, 111],\n",
        "    'Name': ['John Doe', 'Jane Smith', 'Robert Brown', 'Emily Davis', 'Michael Wilson', \n",
        "             'Sarah Miller', 'David Garcia', 'Jennifer Martinez', 'James Anderson', 'John Doe', 'Lisa Thomas', 'Paul Jackson'],\n",
        "    'Age': [28, 34, np.nan, 22, 45, 200, 31, np.nan, 29, 28, 39, 25],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'new york', 'Houston', \n",
        "             'New_York', 'Chicago', 'San Diego', 'Dallas', 'New York', 'Miami', 'NY'],\n",
        "    'Salary': ['50000', '60000', '55000', '48000', '70000', '65000', '52000', '58000', '62000', '50000', '75000', '$54000'],\n",
        "    'JoinDate': ['2020-01-15', '2019-05-20', '2021-02-10', '2020-01-15', '2018-11-05', \n",
        "                 '2021-06-30', '2019-09-12', '2020-08-25', '2021-01-01', '2020-01-15', '2017-03-18', '2020/12/12']\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the first few rows\n",
        "df.head(12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Inspection\n",
        "\n",
        "Before cleaning, we must inspect the data to identify issues. We use methods like `.info()`, `.describe()`, and `.isnull()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check data types and non-null counts\n",
        "print(\"--- Data Info ---\")\n",
        "df.info()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\n--- Missing Values ---\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observations:**\n",
        "-   `Age` has missing values.\n",
        "-   `Salary` is of type `object` (string) instead of integer/float, likely due to the '$' sign.\n",
        "-   `City` has inconsistent naming (New York, new york, New_York, NY)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Handling Duplicates\n",
        "\n",
        "Duplicate rows can skew analysis. We should identify and remove them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for duplicates\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicates}\")\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Verify\n",
        "print(f\"Number of duplicate rows after cleaning: {df.duplicated().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Handling Missing Values\n",
        "\n",
        "We have missing values in the `Age` column. We can either:\n",
        "1.  **Drop** the rows with missing data (if we have a lot of data).\n",
        "2.  **Impute** (fill) the missing data with the Mean, Median, or Mode.\n",
        "\n",
        "Here, we will fill missing `Age` with the **median** age, as it is robust to outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing Age with the median\n",
        "median_age = df['Age'].median()\n",
        "df['Age'] = df['Age'].fillna(median_age)\n",
        "\n",
        "# Verify\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Fixing Inconsistent Data (Standardization)\n",
        "\n",
        "The `City` column has variations for \"New York\". We need to standardize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check unique values\n",
        "print(\"Cities before cleaning:\", df['City'].unique())\n",
        "\n",
        "# Standardize to lowercase and strip whitespace\n",
        "df['City'] = df['City'].str.lower().str.strip()\n",
        "\n",
        "# Replace variations\n",
        "df['City'] = df['City'].replace({'new_york': 'new york', 'ny': 'new york'})\n",
        "\n",
        "# Capitalize for display\n",
        "df['City'] = df['City'].str.title()\n",
        "\n",
        "print(\"Cities after cleaning:\", df['City'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Data Type Conversion and Cleaning Strings\n",
        "\n",
        "The `Salary` column is a string because of the '$' symbol in one entry. We need to remove it and convert the column to numeric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove '$' and convert to numeric\n",
        "df['Salary'] = df['Salary'].astype(str).str.replace('$', '', regex=False)\n",
        "df['Salary'] = pd.to_numeric(df['Salary'])\n",
        "\n",
        "print(df['Salary'].dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Handling Outliers\n",
        "\n",
        "We noticed an `Age` of 200, which is impossible. This is an outlier. We can visualize it and then remove or cap it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize with a Boxplot\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x=df['Age'])\n",
        "plt.title(\"Age Distribution (with Outlier)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove rows where Age is greater than 100\n",
        "df = df[df['Age'] <= 100]\n",
        "\n",
        "# Verify\n",
        "print(\"Max Age:\", df['Age'].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Conclusion\n",
        "\n",
        "We have successfully cleaned our dataset! \n",
        "\n",
        "**Summary of actions:**\n",
        "1.  Removed duplicates.\n",
        "2.  Filled missing values in `Age`.\n",
        "3.  Standardized `City` names.\n",
        "4.  Converted `Salary` to numeric.\n",
        "5.  Removed impossible `Age` outliers.\n",
        "\n",
        "The data is now ready for analysis or machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final look at the clean data\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "combined = pd.concat([df, main_df], axis=1)\n",
        "display(combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preproccesing for LLM "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Model and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "print(\"⏳ Loading Tokenizer (this may take a moment)...\")\n",
        "# We use a multilingual tokenizer to demonstrate sub-word splitting effectively\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# PART A: Tokenization (The Engine of LLMs)\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PART A: Sub-word Tokenization Explained\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Examples: Simple English vs. Complex/Hyphenated words\n",
        "texts = [\n",
        "    \"The AI model is fast.\",           # Simple words\n",
        "    \"Unbelievably good results!\",      # Complex suffix\n",
        "    \"Pre-processing is essential.\",    # Hyphenated\n",
        "    \"Ryan_Heida\"\n",
        "]\n",
        "\n",
        "for txt in texts:\n",
        "    # 1. Tokenize text\n",
        "    tokens = tokenizer.tokenize(txt)\n",
        "    # 2. Convert to IDs (what the model actually sees)\n",
        "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    \n",
        "    print(f\"\\n[Input]:  {txt}\")\n",
        "    print(f\"[Tokens]: {tokens}\")\n",
        "    print(f\"[IDs]:    {ids}\")\n",
        "    print(f\"[Count]:  {len(tokens)} tokens\")\n",
        "\n",
        "print(\"\\n>>> KEY INSIGHT: Notice symbols like '##'. This is 'Sub-word Tokenization'.\")\n",
        "print(\">>> Rare words are broken down into smaller chunks to save vocabulary space.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Duplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# PART B: Deduplication (Quality Control)\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PART B: Data Deduplication (Exact vs. Fuzzy)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Simulating three documents from a web crawl\n",
        "doc_original = \"Deep Learning uses neural networks with many layers.\"\n",
        "doc_exact    = \"Deep Learning uses neural networks with many layers.\"       # 100% Copy\n",
        "doc_fuzzy    = \"Deep Learning utilizes neural nets having multiple layers.\" # Semantic Copy\n",
        "\n",
        "def get_similarity(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "# 1. Exact Match Check\n",
        "print(f\"1. Exact Match Check (Original vs Copy): {'MATCH' if doc_original == doc_exact else 'NO MATCH'}\")\n",
        "\n",
        "# 2. Fuzzy Match Check (MinHash logic simulation)\n",
        "sim_score = get_similarity(doc_original, doc_fuzzy)\n",
        "print(f\"2. Fuzzy Similarity Score: {sim_score:.2f} (Scale 0-1)\")\n",
        "\n",
        "# Decision Logic\n",
        "dedup_threshold = 0.75\n",
        "if sim_score > dedup_threshold:\n",
        "    print(f\">>> DECISION: DROP the fuzzy copy. (Too similar, risks data leakage).\")\n",
        "else:\n",
        "    print(f\">>> DECISION: KEEP the fuzzy copy.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instruction Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### My Template (For My Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ==========================================\n",
        "# PART C: Instruction Tuning (Chat Templates)\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PART C: Formatting for Instruction Fine-Tuning\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Raw data from the internet\n",
        "raw_fact = \"The Eiffel Tower is located in Paris, France.\"\n",
        "\n",
        "\n",
        "# My Chat Template\n",
        "chat_template = \"\"\"{% for message in messages -%}\n",
        "{{ message.role }}: {{ message.content }}\n",
        "{% endfor %}\"\"\"\n",
        "\n",
        "# Converting raw data into a Conversational Format (ChatML style)\n",
        "# This is required for training models like Llama 3, ChatGPT, etc.\n",
        "chat_entry = [\n",
        "    {\"role\": \"system\",    \"content\": \"You are a helpful geography assistant.\"},\n",
        "    {\"role\": \"user\",      \"content\": \"Where is the Eiffel Tower?\"},\n",
        "    {\"role\": \"assistant\", \"content\": raw_fact}\n",
        "]\n",
        "\n",
        "# Apply the template to format the string\n",
        "formatted_string = tokenizer.apply_chat_template(\n",
        "    chat_entry,\n",
        "    chat_template=chat_template,\n",
        "    tokenize=False\n",
        ")\n",
        "\n",
        "print(\"--- Final Training Sample ---\")\n",
        "print(formatted_string)\n",
        "print(\"-----------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use a model tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Login to HF\n",
        "\n",
        "from huggingface_hub import login\n",
        "login()  # then paste your token when prompted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ==========================================\n",
        "# PART C: Instruction Tuning (Chat Templates)\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PART C: Formatting for Instruction Fine-Tuning\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Raw data from the internet\n",
        "raw_fact = \"The Eiffel Tower is located in Paris, France.\"\n",
        "\n",
        "# Converting raw data into a Conversational Format (ChatML style)\n",
        "# This is required for training models like Llama 3, ChatGPT, etc.\n",
        "chat_entry = [\n",
        "    {\"role\": \"system\",    \"content\": \"You are a helpful geography assistant.\"},\n",
        "    {\"role\": \"user\",      \"content\": \"Where is the Eiffel Tower?\"},\n",
        "    {\"role\": \"assistant\", \"content\": raw_fact}\n",
        "]\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\n",
        "\n",
        "formatted_string = tokenizer.apply_chat_template(\n",
        "    chat_entry,\n",
        "    tokenize=False\n",
        ")\n",
        "\n",
        "\n",
        "print(\"--- Final Training Sample ---\")\n",
        "print(formatted_string)\n",
        "print(\"-----------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* **`<|im_start|>`**: Marks the **start** of a speaker's turn.\n",
        "* **`system`**: Defines the model's **persona/rules**.\n",
        "* **`user`**: Contains the **user's instruction/query**.\n",
        "* **`assistant`**: Contains the **target response** for the model to learn.\n",
        "* **`<|im_end|>`**: Marks the **end** of a speaker's turn."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
